{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import CIFAR10_captioning\n",
    "from vgg import vgg13_bn\n",
    "from lstm import lstm\n",
    "from encdec_model import EncoderDecoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CIFAR10-captioning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = os.path.join(os.getcwd(), '../', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))])\n",
    "\n",
    "# make download true to download data!\n",
    "trainset = CIFAR10_captioning(root=data_dir_path, train=True, download=False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset = CIFAR10_captioning(root=data_dir_path, train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = vgg13_bn(pretrained=True, device=device).to(device)\n",
    "decoder = lstm(10, 16, 1, len(trainset.vocab)).to(device)\n",
    "model = EncoderDecoder(encoder, decoder).to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critertion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverage():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_training_loss = RunningAverage()\n",
    "running_training_acc = RunningAverage()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, captions, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        captions = captions.to(device)\n",
    "        target_length = captions.size(1) - 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs, target_length) # (batch_size, target_length, vocab_size)\n",
    "        loss = critertion(outputs, captions[:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_training_loss.update(loss.item(), inputs.size(0))\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        correct = (predicted == captions[:, 1:]).sum().item()\n",
    "        running_training_acc.update(correct, inputs.size(0))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {_}, Batch: {i}, Loss: {running_training_loss()}, Accuracy: {running_training_acc()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('exp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43f91b173d8def8e0128e1c42258763c853c5fa6ce6e2f0b9aa0218077c9004a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
