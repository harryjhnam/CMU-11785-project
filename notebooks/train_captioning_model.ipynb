{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f4_u4/.conda/envs/exp/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_cuda.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import CIFAR10_captioning\n",
    "from vgg import vgg13_bn\n",
    "from lstm import lstm\n",
    "from encdec_model import EncoderDecoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CIFAR10-captioning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = os.path.join(os.getcwd(), '../', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))])\n",
    "\n",
    "# make download true to download data!\n",
    "trainset = CIFAR10_captioning(root=data_dir_path, train=True, download=False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset = CIFAR10_captioning(root=data_dir_path, train=False, download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "EncoderDecoder                           [1, 6, 16]                --\n",
       "├─VGG: 1-1                               [1, 10]                   --\n",
       "│    └─Sequential: 2-1                   [1, 512, 1, 1]            --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 32, 32]           1,792\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 32, 32]           36,928\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 32, 32]           --\n",
       "│    │    └─MaxPool2d: 3-7               [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-8                  [1, 128, 16, 16]          73,856\n",
       "│    │    └─BatchNorm2d: 3-9             [1, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-10                   [1, 128, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-11                 [1, 128, 16, 16]          147,584\n",
       "│    │    └─BatchNorm2d: 3-12            [1, 128, 16, 16]          256\n",
       "│    │    └─ReLU: 3-13                   [1, 128, 16, 16]          --\n",
       "│    │    └─MaxPool2d: 3-14              [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-15                 [1, 256, 8, 8]            295,168\n",
       "│    │    └─BatchNorm2d: 3-16            [1, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-17                   [1, 256, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-18                 [1, 256, 8, 8]            590,080\n",
       "│    │    └─BatchNorm2d: 3-19            [1, 256, 8, 8]            512\n",
       "│    │    └─ReLU: 3-20                   [1, 256, 8, 8]            --\n",
       "│    │    └─MaxPool2d: 3-21              [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-22                 [1, 512, 4, 4]            1,180,160\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-24                   [1, 512, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-25                 [1, 512, 4, 4]            2,359,808\n",
       "│    │    └─BatchNorm2d: 3-26            [1, 512, 4, 4]            1,024\n",
       "│    │    └─ReLU: 3-27                   [1, 512, 4, 4]            --\n",
       "│    │    └─MaxPool2d: 3-28              [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-29                 [1, 512, 2, 2]            2,359,808\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-31                   [1, 512, 2, 2]            --\n",
       "│    │    └─Conv2d: 3-32                 [1, 512, 2, 2]            2,359,808\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 512, 2, 2]            1,024\n",
       "│    │    └─ReLU: 3-34                   [1, 512, 2, 2]            --\n",
       "│    │    └─MaxPool2d: 3-35              [1, 512, 1, 1]            --\n",
       "│    └─AdaptiveAvgPool2d: 2-2            [1, 512, 1, 1]            --\n",
       "│    └─Sequential: 2-3                   [1, 10]                   --\n",
       "│    │    └─Linear: 3-36                 [1, 4096]                 2,101,248\n",
       "│    │    └─ReLU: 3-37                   [1, 4096]                 --\n",
       "│    │    └─Dropout: 3-38                [1, 4096]                 --\n",
       "│    │    └─Linear: 3-39                 [1, 4096]                 16,781,312\n",
       "│    │    └─ReLU: 3-40                   [1, 4096]                 --\n",
       "│    │    └─Dropout: 3-41                [1, 4096]                 --\n",
       "│    │    └─Linear: 3-42                 [1, 10]                   40,970\n",
       "├─Linear: 1-2                            [1, 16]                   176\n",
       "├─LSTM: 1-3                              [1, 1, 16]                --\n",
       "│    └─LSTM: 2-4                         [1, 1, 32]                6,400\n",
       "│    └─Linear: 2-5                       [1, 16]                   528\n",
       "│    └─Softmax: 2-6                      [1, 16]                   --\n",
       "├─LSTM: 1-4                              [1, 1, 16]                (recursive)\n",
       "│    └─LSTM: 2-7                         [1, 1, 32]                (recursive)\n",
       "│    └─Linear: 2-8                       [1, 16]                   (recursive)\n",
       "│    └─Softmax: 2-9                      [1, 16]                   --\n",
       "├─LSTM: 1-5                              [1, 1, 16]                (recursive)\n",
       "│    └─LSTM: 2-10                        [1, 1, 32]                (recursive)\n",
       "│    └─Linear: 2-11                      [1, 16]                   (recursive)\n",
       "│    └─Softmax: 2-12                     [1, 16]                   --\n",
       "├─LSTM: 1-6                              [1, 1, 16]                (recursive)\n",
       "│    └─LSTM: 2-13                        [1, 1, 32]                (recursive)\n",
       "│    └─Linear: 2-14                      [1, 16]                   (recursive)\n",
       "│    └─Softmax: 2-15                     [1, 16]                   --\n",
       "├─LSTM: 1-7                              [1, 1, 16]                (recursive)\n",
       "│    └─LSTM: 2-16                        [1, 1, 32]                (recursive)\n",
       "│    └─Linear: 2-17                      [1, 16]                   (recursive)\n",
       "│    └─Softmax: 2-18                     [1, 16]                   --\n",
       "├─LSTM: 1-8                              [1, 1, 16]                (recursive)\n",
       "│    └─LSTM: 2-19                        [1, 1, 32]                (recursive)\n",
       "│    └─Linear: 2-20                      [1, 16]                   (recursive)\n",
       "│    └─Softmax: 2-21                     [1, 16]                   --\n",
       "==========================================================================================\n",
       "Total params: 28,341,514\n",
       "Trainable params: 28,341,514\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 247.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 4.06\n",
       "Params size (MB): 113.37\n",
       "Estimated Total Size (MB): 117.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output_size = len(trainset.classes)\n",
    "decoder_output_size = len(trainset.vocab)\n",
    "\n",
    "encoder = vgg13_bn(pretrained=True, device=device).to(device)\n",
    "decoder = lstm(len(trainset.vocab), 32, 1, len(trainset.vocab)).to(device)\n",
    "model = EncoderDecoder(encoder, decoder, encoder_output_size=encoder_output_size, decoder_output_size=decoder_output_size).to(device)\n",
    "summary(model, input_size=(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 0.1\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteration = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverage():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, value, n=1):\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criteration, optimizer, trainloader):\n",
    "    model.train()\n",
    "\n",
    "    running_training_loss = RunningAverage()\n",
    "    running_training_acc = RunningAverage()\n",
    "    \n",
    "    for inputs, (captions, labels) in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) # (batch_size, target_length, vocab_size)\n",
    "        loss = criteration(outputs.permute(0,2,1), captions[:,1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_training_loss.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        correct = (predicted == captions[:, 1:]).sum().item()\n",
    "        running_training_acc.update(correct/(inputs.size(0)*6), inputs.size(0))\n",
    "\n",
    "    return running_training_loss(), running_training_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criteration, testloader, n_examples=-1):\n",
    "    model.eval()\n",
    "\n",
    "    running_test_loss = RunningAverage()\n",
    "    running_test_acc = RunningAverage()\n",
    "\n",
    "    for inputs, (captions, labels) in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "        captions = captions.to(device)\n",
    "        target_length = captions.size(1) - 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criteration(outputs.permute(0,2,1), captions[:,1:])\n",
    "        \n",
    "        running_test_loss.update(loss.item(), inputs.size(0))\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        correct = (predicted == captions[:, 1:]).sum().item()\n",
    "        running_test_acc.update(correct/(inputs.size(0)*target_length), inputs.size(0))\n",
    "\n",
    "    if n_examples != -1:\n",
    "        return running_test_loss(), running_test_acc(), inputs[:n_examples], predicted[:n_examples]\n",
    "    else:\n",
    "        return running_test_loss(), running_test_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 2.0714442247009277, Training Accuracy: 0.8333333333333338, Test Loss: 2.066313655471802, Test Accuracy: 0.833333333333333\n",
      "Epoch: 1, Training Loss: 2.0628743252563475, Training Accuracy: 0.8333333333333338, Test Loss: 2.059933357620239, Test Accuracy: 0.833333333333333\n",
      "Epoch: 2, Training Loss: 2.0578512464904786, Training Accuracy: 0.8333333333333338, Test Loss: 2.0560204425811768, Test Accuracy: 0.833333333333333\n",
      "Epoch: 3, Training Loss: 2.0546613621520997, Training Accuracy: 0.8333333333333338, Test Loss: 2.0534371028900145, Test Accuracy: 0.833333333333333\n",
      "Epoch: 4, Training Loss: 2.052493119735718, Training Accuracy: 0.8333333333333338, Test Loss: 2.051624613571167, Test Accuracy: 0.833333333333333\n",
      "Epoch: 5, Training Loss: 2.050934086532593, Training Accuracy: 0.8333333333333338, Test Loss: 2.050286424255371, Test Accuracy: 0.833333333333333\n",
      "Epoch: 6, Training Loss: 2.049757568588257, Training Accuracy: 0.8333333333333338, Test Loss: 2.049253356552124, Test Accuracy: 0.833333333333333\n",
      "Epoch: 7, Training Loss: 2.048831484298706, Training Accuracy: 0.8333333333333338, Test Loss: 2.0484228351593017, Test Accuracy: 0.833333333333333\n",
      "Epoch: 8, Training Loss: 2.0480734378051757, Training Accuracy: 0.8333333333333338, Test Loss: 2.0477292888641356, Test Accuracy: 0.833333333333333\n",
      "Epoch: 9, Training Loss: 2.0474309744262693, Training Accuracy: 0.8333333333333338, Test Loss: 2.047133682632446, Test Accuracy: 0.833333333333333\n",
      "Epoch: 10, Training Loss: 2.0468723056793214, Training Accuracy: 0.8333333333333338, Test Loss: 2.0466098606109617, Test Accuracy: 0.833333333333333\n",
      "Epoch: 11, Training Loss: 2.0463800608062743, Training Accuracy: 0.8333333333333338, Test Loss: 2.0461480628967283, Test Accuracy: 0.833333333333333\n",
      "Epoch: 12, Training Loss: 2.0459452414703367, Training Accuracy: 0.8333333333333338, Test Loss: 2.0457405883789064, Test Accuracy: 0.833333333333333\n",
      "Epoch: 13, Training Loss: 2.04556358253479, Training Accuracy: 0.8333333333333338, Test Loss: 2.0453837013244627, Test Accuracy: 0.833333333333333\n",
      "Epoch: 14, Training Loss: 2.0452293682861327, Training Accuracy: 0.8333333333333338, Test Loss: 2.0450724254608152, Test Accuracy: 0.833333333333333\n",
      "Epoch: 15, Training Loss: 2.044938066177368, Training Accuracy: 0.8333333333333338, Test Loss: 2.044800054550171, Test Accuracy: 0.833333333333333\n",
      "Epoch: 16, Training Loss: 2.0446829105377198, Training Accuracy: 0.8333333333333338, Test Loss: 2.0445613437652588, Test Accuracy: 0.833333333333333\n",
      "Epoch: 17, Training Loss: 2.04445948387146, Training Accuracy: 0.8333333333333338, Test Loss: 2.0443524955749512, Test Accuracy: 0.833333333333333\n",
      "Epoch: 18, Training Loss: 2.0442629722595216, Training Accuracy: 0.8333333333333338, Test Loss: 2.044167673110962, Test Accuracy: 0.833333333333333\n",
      "Epoch: 19, Training Loss: 2.044088697128296, Training Accuracy: 0.8333333333333338, Test Loss: 2.0440043750762937, Test Accuracy: 0.833333333333333\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    train_loss, train_acc = train(model, criteration, optimizer, trainloader)\n",
    "    \n",
    "    if e == epochs - 1:\n",
    "        test_loss, test_acc, example_images, example_captions = test(model, criteration, testloader, n_examples=4)\n",
    "    else:\n",
    "        test_loss, test_acc = test(model, criteration, testloader)\n",
    "\n",
    "    print(f\"Epoch: {e}, Training Loss: {train_loss}, Training Accuracy: {train_acc}, Test Loss: {test_loss}, Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3, 15, 15],\n",
       "        [ 0,  1,  2,  3, 15, 15],\n",
       "        [ 0,  1,  2,  3, 15, 15],\n",
       "        [ 0,  1,  2,  3, 15, 15]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('exp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c589a571bd5341dfd2a827c9395c768a2b8d426312196b17f0ed2e2404844f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
